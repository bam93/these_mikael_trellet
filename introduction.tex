%\chapterstar{INTRODUCTION}
% Pour des renseignements sur \chapterstar : voir le fichier macros.tex

\chapter*{Introduction} % "*" pour que l'introduction ne s'affiche pas dans la table des matières, sinon elle s'y affichera comme un chapitre d
\mtcaddchapter
\addstarredpart{INTRODUCTION} % Pour ajouter une partie ("part") fictive dans la table des matières
\mtcaddpart
\markboth{Introduction}{Introduction}  %% header manuel car sinon, ils me marquent le header du dernier \chapter{?} (on est dans un \chapter*{?} )
\selectlanguage{francais}

L'introduction nous permettra tout d'abord de poser le contexte et la problématique liés au sujet de la thèse. Dans un deuxième temps, nous exposerons brièvement l'approche générale choisie afin de répondre à cette problématique et enfin nous présenterons un plan général du manuscrit.

\subsection*{Contexte et problématique}

En science, la performance croissante des outils de calcul informatique permet aujourd'hui de générer des volumes de données considérables. Ceci est particulièrement vrai pour le domaine de la biologie structurale qui voit ses modèles moléculaires croître rapidement, à la fois en précision et en taille. Cette complexité grandissante est rendue possible par l'efficacité croissante des programmes de simulation. Ces derniers peuvent désormais générer des images décrivant l'évolution temporelle à une précision atomique pour des structures moléculaires pouvant atteindre plusieurs millions de particules. L'augmentation des moyens de calcul n'est malheureusement pas directement corrélée à l'augmentation des moyens d'analyse et la quantité générée de données est bien souvent très supérieure à la quantité de données traitée par les experts scientifiques. De même, les capacités de calcul ont depuis longtemps dépassé les capacités de stockage, pourtant elles-mêmes en croissance permanente. Enfin, la taille des données impacte directement l'efficacité et la rapidité des communications entre les machines impliquées dans le processus de calcul. La minimisation des échanges de données, de la quantité de données à stocker et à analyser suite à d'importants calculs est donc aujourd'hui un enjeu crucial pour le traitement des données scientifiques.

Il est possible de diviser la biologie structurale et donc l'étude théorique de structures moléculaires en quatre activités principales organisées selon le processus séquentiel suivant: la collecte de données expérimentales ou théoriques, la visualisation des structures 3d, la simulation moléculaire, l’analyse et l’interprétation des résultats. Il n'est pas rare que plusieurs itérations de ce processus soient nécessaires à l'établissement d'une conclusion scientifique significative pour le phénomène biologique étudié. Chaque nouveau processus prenant comme données d'entrée une partie des résultats générés par l'analyse des données du processus précédent.  

L'ajout d'un moyen de contrôle sur la génération des données, parallèlement à la simulation, pourrait permettre de filtrer les données obtenues. Ce contrôle doit impérativement être sans pertes pour la compréhension finale du phénomène étudié. L'approche \textit{in situ} répond en partie à la problématique du contrôle des données en mettant en place des outils pour le calcul, l'analyse et le rendu de données de simulation numérique à travers des solutions technologiques de haute performance permettant le suivi en temps interactif d'une simulation moléculaire. Une synchronisation est ainsi possible entre une simulation tournant en arrière-plan, son rendu visuel et les analyses associées permet à l'utilisateur de contrôler et diriger sa simulation suivant les données d'analyse et de visualisation obtenus. L'effort technologique et les problématiques de performance de l'approche \textit{in situ} freinent cependant l'apport d'interactions fine entre la simulation, le rendu et les analyses et ainsi ces modules sont souvent dissociés. De plus, la simulation étant souvent déporté sur des sites de calcul distants, se pose la question de la sécurité des données qui transitent entre des sites distants et la difficulté pour y accéder dans des conditions optimales afin de mettre en place une synchronisation cohérente. Les performances réseau ne permettent pas encore d'assurer un temps de transport des données suffisant pour que les grands centres de calculs puissent fournir à tout instant les données des simulations qu'ils hébergent aux laboratoires scientifiques.
Il est donc possible dans une certaine mesure d'automatiser ce filtrage des données mais il reste un besoin évident pour l'expertise humaine afin d'avoir un impact réel et positif. 
\commentaire{Faire attention ici on sous entend que des approches pour résoudre ce problème n'existent pas, alors que certaine de type calcul/analyse/rendu InSitu essayent de résoudre le problème, c'est la différence entre notre approche et InSitu qu'il faut appuyer}
\correction{Ok}

La volonté de mettre l'expert scientifique au centre de la boucle de décision passe par la mise en place d'éléments d'analyse et de visualisation appropriés. Ceux-ci doivent permettre de présenter les données de façon à ce que l'utilisateur puisse appréhender dans les meilleures conditions le phénomène observé. Ces deux composantes, visuelles et analytiques, amènent avec elles des problématiques précises auxquelles il est nécessaire de répondre pour pouvoir implémenter tout élément supplémentaire de contrôle. Tout d'abord, la taille des systèmes moléculaires ne cessant d'augmenter, la visualisation de ceux-ci doit passer par des espaces plus importants et plus adaptés.

Le traitement analytique des données se fait en parallèle de leur observation et peut constituer un espace indépendant mais se doit cependant d'être cohérent avec le rendu visuel des données. La dimension immersive apporte une première réponse à ces problèmes en fournissant un espace d'affichage suffisamment important pour traiter des complexes moléculaires entiers dans leur environnement. Cet espace d'affichage plus important se fait soit par des dispositifs de grande taille où l'utilisateur peut évoluer tout en ayant son point de vue adapté suivant sa position et son orientation (systèmes CAVE, murs d'écrans, etc...), soit par des dispositifs de taille plus réduite et portable mais à travers lesquels l'utilisateur peut percevoir un monde virtuel à 360 degrés (casques stéréoscopiques, etc...). De plus, la réalité virtuelle offre une perception stéréoscopique de haute qualité indispensable pour une meilleure compréhension des données moléculaires intrinsèquement tridimensionnelles. Même si moins utilisés en biologie structurale, les canaux auditifs et tactiles sont aussi concernés par les développement en réalité virtuelle. L'audio 3d permettant de simuler des sources audio dans un environnement 3d autour de l'utilisateur et les retours haptiques associés à certains dispositifs d'interaction permettent de ressentir davantage l'immersion dans un monde virtuel donné dans la limite de cohérence de leur implémentation. 

Cependant, l'immersion comporte également ses limites. La navigation au sein de dispositifs immersifs dans des données abstraites est un premier obstacle. Découlant de la navigation au sein de scènes virtuelles immersives et également présent pour des scènes réalistes, par opposition aux scènes illustrant des données abstraites, le mal du simulateur est un frein non négligeable à l'expérience de l'utilisateur. Ce phénomène de gène pour l'utilisateur dégrade significativement son expérience et ses performances dans les environnements immersifs. Plusieurs études ont montré que ce mal du simulateur possède plusieurs points communs avec le mal des transports. De la même façon que pour le mal des transports, dans un environnement immersif, le cerveau éprouve une certaine difficulté à dissocier les perceptions visuelles de l'utilisateur à l'implication physique de son corps. Bien souvent, cela est dû à une dissociation de la sollicitation du système vestibulaire par rapport au système perceptif. Cette différence de sollicitation entraîne chez certaines personnes un malaise qui peut aller de légères sensations d'inconfort à de plus importants troubles de l'équilibre ou de nausées. Les paradigmes de navigation en conditions immersives sont multiples mais ont pour la plupart une utilisation ciblée et difficilement généralisables. Ils ont souvent été développé pour répondre à des contraintes de navigation dans des scènes écologiques précises et donc ne parviennent pas à répondre aux attentes d'efficacité dans des scènes virtuelles dont les informations proposées sont de nature différente. Cette absence de compatibilité entre les scènes réalistes et abstraites peut s'expliquer par: 1) une absence de repères spatiaux dans les scènes abstraites où les données scientifiques ne sont généralement pas exposées au sein d'un environnement mais dans un espace vide monochromatique, 2) une absence de notion d'orientation, sans haut ni bas, 3) une exploration centrée sur un objet unique au centre de l'attention. Ces trois points ne peuvent être dissociés de toute mise en place de paradigmes de navigation pour la biologie structurale et les données scientifiques en général.

En parallèle de la navigation, les interactions entre l'utilisateur et son espace de travail dans un environnement immersif sont limitées par l'absence de dispositifs précis comme la combinaison clavier/souris en conditions standards. Afin de garantir une immersion optimale, les menus et commandes textuelles habituelles sont mis de côté au profit d'interactions plus naturelles déclenchées par des interactions directes avec les objets virtuels présentés via des gestes et/ou par des commandes vocales. Ces interactions peuvent également s'appuyer sur certains dispositifs adaptés aux espaces immersifs mais ces derniers comportent un nombre d'entrées limités qui nécessitent d'être également optimisés pour pouvoir déclencher l'ensemble des actions nécessaires au sein d'un espace de travail en biologie structurale. Parmi celles-ci, sélection, changement de rendu, mouvement, accès aux informations sont plusieurs actions importantes en visualisation moléculaire. A ces commandes s'ajoutent toutes les actions propres aux espaces d'analyse et permettant d'interagir avec des graphes. Afin de garantir une optimisation profonde de la couche d'interaction entre l'utilisateur et les espaces de travail, il est donc nécessaire de mettre en place une méthode robuste permettant d'anticiper et de simplifier les étapes d'interaction permettant d'accomplir chaque tâche pouvant être accomplie. 

Nos développements doivent faire face à deux contraintes temporelles importantes. Ces contraintes, en filigrane tout au long de notre étude, ont motivé nos choix techniques pour assurer à l'utilisateur une expérience immersive de travail au moins aussi efficace que dans des conditions standards de bureau.
La première contrainte est la contrainte de temps réel que nous impose la plupart des environnements immersifs lorsqu'il est question de rendu stéréoscopique s'adaptant au point de vue utilisateur. Il est nécessaire de s'approcher de communication temps réel pour réduire au strict minimum la latence entre les mouvements de l'utilisateur et le rendu calculé pour la nouvelle position et orientation de l'utilisateur à chaque instant. Nous nous appuyons essentiellement sur des briques techniques et technologiques qui ont déjà prouvé leur efficacité pour le rendu 3d temps réel, il est donc nécessaire que nos apports, en particulier pour la navigation et l'exploration, ne soient pas un frein à l'immersion et au rendu temps réel qui lui est propre.
La deuxième contrainte temporelle vient de la contrainte interactive inhérente à tout système où l'action de l'utilisateur induit un changement visuel ou structurel de la scène et des informations qu'il perçoit. Cette contrainte en temps interactif fut un point important du développement de notre liaison bi-latérale entre espace d'exploration et espace d'analyses. Ce temps interactif doit se rapprocher au maximum de ce que pourrait attendre l'utilisateur, en terme de retours sensoriels, lors du déclenchement d'une action. Il n'est souvent pas nécessaire que l'action voit sa réalisation s'effectuer en temps réel, c'est pourquoi nous parlerons de temps interactif.

 
\subsection*{Approche générale}

Notre première démarche dans ce travail de thèse fut de fournir un premier contrôle de l'évolution d'une simulation moléculaire à un expert scientifique. Ce contrôle doit permettre d'appréhender la direction vers laquelle tend la simulation et éventuellement mettre en évidence une évolution ne respectant pas les contraintes imposées et l'évolution attendue. Afin de permettre un contrôle sur des données de taille importante et au sein d'une simulation étant en cours d’exécution, nous avons choisi de mettre en place une méthode de capture d'image simple permettant de visualiser sur n'importe quelle plateforme, un aperçu pseudo-3d de la structure étudiée. La légèreté des images utilisées pour ce rendu et le développement axé multi-plateforme de notre application, permet également son utilisation au sein de communications scientifiques diverses (journaux papier, journaux électroniques, actes de conférences, etc...) afin d’accroître la quantité d'information présentée. A la différence des images 2d habituelles, notre méthode permet un rendu pseudo-3d pour des illustrations complexes constituées de plusieurs couches et/ou affichant un objet désirant être affiché en profondeur. Un rendu 3d sous forme de visualiseur 3d est associé à l'application pour des structures entières de molécules dont les structures 3d ont été rendues disponibles en ligne.

Motivé par le manque de paradigmes de navigation spécifiques au domaine de la biologie structural, notre second axe de travail s'est concentré sur le développement de méthodes de navigation basées sur le contenu et la tâche en biologie structurale. Ces méthodes et paradigmes s'inspirent de la nature géométrique de la plupart des complexes moléculaires. Nos développements ne sont néanmoins aucunement contraints à des complexes moléculaires symétriques puisque toute structure particulière retrouvée au sein d'une molécule nous permet de mettre en place nos paradigmes de navigation. Grâce à ces paradigmes, tout au long de son exploration, l'utilisateur 1) garde un point de vue stabilisé, 2) possède des repères spatiaux fixes afin de se situer dans la scènes, 3) peut utiliser des chemins optimaux de déplacement pour atteindre des régions d’intérêt. Ces apports répondent respectivement aux problèmes de malaise pouvant être ressentis à cause: 1) d'une variation trop rapide de l'orientation de l'utilisateur par rapport à sa cible visuel, 2) d'une perte de la situation spatiale de l'utilisateur dans sa scène, 3) d'un trop grand nombre d'étapes ou de temps pour atteindre une région d'intérêt tout en gardant une conscience spatiale de la scène virtuelle. En contraignant la navigation à des chemins optimaux, via une restriction des directions du mouvement et des orientations de la caméra, nous assurons un carcan de possibilités limité mais adapté aux interactions simplifiées prenant place au sein des environnements immersifs. De la même manière, nous anticipons certaines tâches d'exploration en fournissant des paradigmes automatisant certains déplacements considérés comme habituels en exploration moléculaire.

Notre troisième sujet d'études s'intéresse à la possibilité de regrouper les espaces de visualisation et d'analyse afin de raccourcir la boucle d'étude des données de simulation moléculaire et ainsi répondre aux problèmes de surcharge de données. Comme exposé précédemment, dans une situation en temps réel, un enjeu majeur est de réduire les données échangées entre les composants de simulation, de visualisation et d'analyse pour permettre à un utilisateur de contrôler ces trois composants de façon optimale et en temps interactif. Sans une intégration fine de ces composants au sein d'une même plateforme logicielle, il est impossible de garantir un réel impact de ce regroupement dans le processus d'étude. En effet, toute incohérence ou hétérogénéité dans les données échangées entre les modules diminue la généricité de l'approche et la ré-utilisabilité de l'application et potentiellement du contrôle de l'utilisateur sur ces modules de façon synchronisée. Notre approche a donc été de mettre en place une couche d'abstraction supplémentaire décrivant données utilisées par les modules manipulés usuellement par les experts du domaine. Cette couche d'abstraction a pu être mise en place par la construction d'une ontologie et d'une sémantique précise des concepts mis en jeu lors de la visualisation et l'analyse de structures moléculaires statiques ou au cours d'une simulation. Nous avons pu nous baser sur cette description ontologique pour construire une base de données liées, directement inspirée de ce qui peut être fait dans le web sémantique, afin de regrouper et classifier l'ensemble des données mises en jeu lors d'une session de travail spécifique et regroupant l'ensemble des informations que possède l'expert scientifique sur son système moléculaire. En restreignant l'utilisation des données par les modules de notre application aux seules données de la base de données, nous pouvons assurer une homogénéité totale de ce qui est manipulé et donc proposer aux utilisateurs des espaces de visualisation et d'analyse mutualisés qui correspondent parfaitement au système d’intérêt étudié. Les utilisateurs possèdent également, à travers l'ontologie mise en place, une suite de règles et de descriptions des concepts qu'ils vont manipuler, leur permettant à la fois de comprendre aisément l'organisation de leurs informations scientifiques au sein de l'application mais également d'enrichir cette organisation via l'élargissement de l'ontologie. L'ontologie mise en place permet enfin de garder une homogénéité forte entre les cas scientifiques. Elle impose un certain carcan pour le formatage des données qui permet finalement un recoupage très aisé des bases de données générées, sans l'inquiétude de la potentielle incompatibilité des données provenant de complexes moléculaires différents.


\commentaire{Intro trop courte et trop générale, une intro est un teaser, on doit pouvoir savoir très précisément ce que tu vends, notamment en terme de scénario et de contribution, tu dois détailler chaque point du résumé}
\correction{Ok, Intro plus longue et descriptive}

\commentaire{Rappeler rapidement la différence entre temps réel et temps interactif}
\correction{Ok}

\subsection*{Plan du manuscrit}
